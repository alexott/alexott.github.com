#title Использование Clojure с Hadoop
#keywords hadoop, clojure

Данная статья является небольшим введение в программирование Hadoop на Clojure.

<contents>

* Введение 

Проект [[http://hadoop.apache.org/][Hadoop]] является свободной реализацией инфраструктуры для распределенных,
масштабируемых вычислений.  Он начался как реализация идей MapReduce и GFS, введенных
Google, но со временем, в рамках проекат были реализованы и другие проекты.  Hadoop
активно используется во многих проектах, включая коммерческие -- Yahoo, LinkedIn, и т.д.,
и позволяет обрабатывать огромные объемы данных используя "стандартное" оборудование.

Hadoop написан на языке Java, что позволяет достаточно просто интегрировать его с Clojure.
Для упрощения программирования на Clojure для Hadoop, [[http://stuartsierra.com/][Stuart Sierra]] разработал достаточно
простой, но мощный пакет =clojure-hadoop=, о котором и пойдет речь в данной статье.

* Установка и настройка 

Установка Hadoop в минимальной конфигурации, необходимой для наших экспериментов,
достаточно проста и описана в [[http://hadoop.apache.org/common/docs/current/quickstart.html][документации]].  Настройка Hadoop для работы в кластере
немного сложнее, но тоже [[http://hadoop.apache.org/common/docs/current/cluster_setup.html][описана достаточно подробно]].

Хочется отметить, что компания Cloudera [[http://www.cloudera.com/developers/downloads/][предоставляет готовые пакеты]] для разных версий
Linux, так что вы можете установить Hadoop и другие пакеты используя ваш любимый пакетный
менеджер.  Кроме того, они распространяют готовую к работе инсталяцию в виде образа для
VMWare, так что вы можете загрузить нужный архив и получить готовую рабочую среду.

Исходные тексты =clojure-hadoop= можно взять с [[http://github.com/stuartsierra/clojure-hadoop][github]] -- она работает с Hadoop версии 0.19 и
Clojure 1.1.0.  Если вам нужен Hadoop 0.20 и старше и/или Clojure 1.2.0, то вы можете
взять [[http://github.com/alexott/clojure-hadoop][версию с моими изменениями]].  Сборка и установка производится с помощью Maven -- для
этого надо всего-лишь выполнить команду =mvn install=.

* Из чего состоит clojure-hadoop

=clojure-hadoop= состоит из нескольких уровней абстракции, которые реализуются с помощью
макросов.  Каждый из уровней находится в отдельном пространстве имен, перечисленных в
порядке увеличения абстракции.
 =clojure-hadoop.gen= :: реализует набор макросов, которые генерируют классы, необходимые
   для определения задания MapReduce.  Функции =map= и =reduce= имеют точно такой же набор
   параметров, как и функции Java и имеют фиксированные имена -- =map-mapper= и
   =reduce-reducer=.  А инициализация задания, указание входных и выходных файлов и т.п.,
   должно производиться функцией =tool-run=.
 =clojure-hadoop.wrap= :: реализует функции-обертки, которые упрощают конвертацию входных и
    выходных данных, позволяя писать функции =map= и =reduce= в более натуральном для Clojure
    стиле.  Все остальное реализуется также как и в предыдущем случае.
 =clojure-hadoop.job= :: реализует все необходимые функции (=map-mapper=, =reduce-reducer= и
   =tool-run=), позволяя указывать названия функций =map= и =reduce= (написанных на Clojure),
   входные и выходные данные и т.п., используя опции командной строки.
 =clojure-hadoop.defjob= :: A convenient macro to configure MapReduce jobs with Clojure
   code.  See the example files "wordcount4.clj" and "wordcount5.clj" for demonstrations
   of this macro.

Кроме того, имеется пространство имен =clojure-hadoop.imports=, в котором определяются
функции для импорта определений классов и интерфейсов Hadoop, что делает жизнь
разработчика легче -- эти функции используются во всех программах, независимо от
выбранного уровня абстракции;

* Как программировать с помощью clojure-hadoop?

В зависимости от выбранного вами уровня абстракции, вам необходимо использовать разные
подходы к программированию.  В большинстве случаев достаточно использовать =defjob=, который
прячет больщую часть деталей за своим интерфейсом, так что программисту достаточно
реализовать логику в виде двух функций.  Однако, в некоторых случаях может понадобиться
использовать низкоуровневые интерфейсы, поэтому тут приводится описание всех уровней.

** Использование clojure-hadoop.gen

wordcount1

** Использование clojure-hadoop.wrap

wordcount2

** Использование clojure-hadoop.job

wordcount3

** Использование clojure-hadoop.defjob

wordcount4 & 5

* Полный пример

В качестве примера хочу показать небольшую программу, которая генерирует наборы [[https://secure.wikimedia.org/wikipedia/en/wiki/N-gram][N-Gram]] из
заданных файлов -- я использую сгенеренные базы для задач классификации документов.
Исходный код доступен на [[http://github.com/alexott/clojure-examples][github]], каталог =hadoop1=.  Данный пример использует =defjob= для
объявления задания и пользовательских функций =map= и =reduce=.

Весь проект состоит из одного файла с исходным кодом, в котором реализуются функции =my-map=
и =my-reduce=, которые затем указываются в описании задания (входные и выходные форматы
функций, исходных и результирующих файлов, и т.д.), для чего используется макрос =defjob=.
Как обычно для MapReduce, функция =my-map= принимает на вход ключ (целое число) и строку, и
выдает список пар строка/целое число, где строка -- выделенный участок слова.  Функция
=my-reduce= очень проста -- она просто суммирует количество вхождений каждого ключа.

<src lang="clojure">
(ns hadoop1
    (:require [clojure-hadoop.wrap :as wrap]
              [clojure-hadoop.defjob :as defjob]
              [clojure-hadoop.imports :as imp])
    (:use clojure.contrib.seq-utils)
    (:require [clojure.contrib.str-utils2 :as str2])
    (:import (java.util StringTokenizer)))

(imp/import-io)
(imp/import-mapred)

(def delimiters "0123456789[ \t\n\r!\"#$%&'()*+,./:;<=>?@\\^`{|}~-]+")

(defn gen-n-grams [#^String s #^Integer n]
  (when (> (.length s) 0)
      (let [str (str " " s (String. ) (str2/repeat " " (- n 1)))]
        (reduce (fn [val elem]
                  (conj val (.substring str elem (+ elem n))))
                []
                (range 0 (+ 1 (.length s)))))))

(defn my-map [key #^String value]
  (map (fn [token] [token 1])
       (flatten (map #(gen-n-grams %1 3)
                     (enumeration-seq (StringTokenizer. value delimiters))))))

(defn my-reduce [key values-fn]
  [ [key (reduce + (values-fn))] ])

(defn string-long-writer [#^OutputCollector output
                          #^String key value]
  (.collect output (Text. key) (LongWritable. value)))

(defn string-long-reduce-reader [#^Text key wvalues]
  [(.toString key)
   (fn [] (map (fn [#^LongWritable v] (.get v))
               (iterator-seq wvalues)))])

(defjob/defjob job
  :map my-map
  :map-reader wrap/int-string-map-reader
  :map-writer string-long-writer
  :reduce my-reduce
  :reduce-reader string-long-reduce-reader
  :reduce-writer string-long-writer
  :output-key Text
  :output-value LongWritable
  :input-format :text
  :output-format :text
  :compress-output false)
</src>

Данный код основан на примере [[http://github.com/stuartsierra/clojure-hadoop/blob/master/src/examples/clojure/clojure_hadoop/examples/wordcount5.clj][wordcount5]] из поставки пакета clojure-hadoop. Для сборки
кода используется следующий проект Leiningen:

<src lang="clojure">
(defproject hadoop1 "1.0"
  :description "hadoop1"
  :dependencies [[org.clojure/clojure "1.1.0"]
                 [org.clojure/clojure-contrib "1.1.0"]
                 [com.stuartsierra/clojure-hadoop "1.2.0-SNAPSHOT"]]
  )
</src>

Для запуска проекта необходимо собрать все библиотеки в один архив, поэтому для сборки
должна использоваться команда =lein uberjar=, которая упакует код на Clojure, вместе со
всеми необходимыми библиотеками.  После сборки вы можете запустить задачу на выполнение
либо в автономном режиме -- без запущенного Hadoop, и работающего с локальными файлами[1],
либо в кластерном режиме.

Запуск в автономном режиме производится следующей командой:

<src lang="sh">
java -cp hadoop1-standalone.jar clojure_hadoop.job -job hadoop1/job -input FILE -output out
</src>

в качестве аргумента =FILE= подставьте нужный текстовый файл, и после выполнения программы,
в каталоге =out= будет создан файл, содержащий список N-Gram и их количество в тексте.
Данный файл можно затем использовать в качестве базы данных для задач определения языков и
т.п.

Для запуска вашего кода в кластере Hadoop вы должны поместить анализируемые файлы на HDFS
(в каталог =input=, в нашем примере), и запустить задачу на выполнение с помощью следуюшей
команды:

<src lang="sh">
hadoop jar hadoop1-standalone.jar clojure_hadoop.job -job hadoop1/job -input input -output output
</src>

После окончания выполнения задания, данные будут помещены в каталог =output=[2] на HDFS, и
вы можете получить доступ к ним используя стандартные команды работы с HDFS.


#more-info
* Заключение

Данная статья является лишь введением в использование Clojure для программирования на базе
Hadoop.  Дополнительные примеры применения clojure-hadoop вы можете найти в следующих
материалах: 
 - [[http://vimeo.com/7669741][Видео-презентация о Clojure и Hadoop на HadoopWorld NYC]] ([[http://stuartsierra.com/2009/10/02/clojurehadoop-slides][слайды]]);
 - [[http://www.bestinclass.dk/index.php/2010/01/hadoop-feeding-reddit-to-hadoop/][Hadoop - Feeding Reddit to Hadoop]] -- заметка в блоге, показывающая использование 
   Clojure & Hadoop для анализа данных, собранных с Reddit.
 - [[http://github.com/stuartsierra/clojure-hadoop/tree/master/src/examples/clojure/clojure_hadoop/examples/][Примеры из поставки]] =clojure-hadoop=

Дополнительная информация о программировании Hadoop и Map/Reduce вы можете найти в
следующих материалах:
 - [[http://www.cloudera.com/hadoop-training-programming-with-hadoop][Видео-лекция о программировании с помощью Hadoop]];
 - [[http://www.cloudera.com/hadoop-training-basic][Учебные курсы по работе с Hadoop созданные компаниией Cloudera]]
 - [[http://hadoop.apache.org/common/docs/current/mapred_tutorial.html][Map/Reduce Tutorial]]
 - [[http://www.amazon.com/gp/product/0596521979?ie=UTF8&amp;tag=aleottshompag-20&amp;linkCode=as2&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0596521979][Hadoop: The Definitive Guide]] -- отличная книга о работе и программировании Hadoop, и
   сопутствующищих проектов -- Pig, HBase, и других;
 - [[http://www.amazon.com/gp/product/1608453421?ie=UTF8&amp;tag=aleottshompag-20&amp;linkCode=as2&amp;camp=1789&amp;creative=390957&amp;creativeASIN=1608453421][Data-Intensive Text Processing with MapReduce]] -- книга об использовании Map/Reduce для
   анализа больших объемов текстовых данных, включая примеры использования Hadoop.




 - добавить описание http://github.com/nathanmarz/cascalog ?


;  LocalWords:  Cloudera Hadoop clojure hadoop VMWare GFS HDFS

Footnotes: 
[1] Запуск в автономном режиме удобен для отладки вашего кода, поскольку он выполняется в
    отдельном инстансе JVM, и работает с локальными файлами.

[2] Каталог для результатов не должен существовать, задание просто не запустится если
    каталог уже существует.

