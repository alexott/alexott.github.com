<html><head><meta http-equiv="Content-Type" content="text/html; charset=utf-8"><title>Фильтрация Интернет-трафика</title><meta name="generator" content="DocBook XSL Stylesheets V1.73.2"><meta name="keywords" content="Content filtering, Data information leakage, trends, Контентная фильтрация, Предотвращение утечки данных, Web filtering, VoIP filtering, Mail filtering, IM filtering, Instant Messaging filtering, UTM"><link rel="start" href="index.html" title="Современные тенденции в области контентной фильтрации"><link rel="up" href="index.html" title="Современные тенденции в области контентной фильтрации"><link rel="prev" href="ar01s03.html" title="Современные угрозы"><link rel="next" href="ar01s05.html" title="Фильтрация почтового трафика"></head><body bgcolor="white" text="black" link="#0000FF" vlink="#840084" alink="#0000FF"><div class="navheader"><table width="100%" summary="Navigation header"><tr><th colspan="3" align="center">Фильтрация Интернет-трафика</th></tr><tr><td width="20%" align="left"><a accesskey="p" href="ar01s03.html">Пред.</a> </td><th width="60%" align="center"> </th><td width="20%" align="right"> <a accesskey="n" href="ar01s05.html">След.</a></td></tr></table><hr></div><div class="section" lang="ru"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="id2522409"></a>Фильтрация Интернет-трафика</h2></div></div></div><p>В последнее время в области фильтрации Интернет-трафика происходят различные изменения, обусловленные появлением новых технологий фильтрации и изменением технологий, которые используются для построения Интернет-сайтов.</p><p>Одной из наиболее важных тенденций развития продуктов контентной фильтрации в части контроля Интернет-трафика является переход от использования баз данных категорий сайтов к определению категории сайта по его содержимому. Это стало особенно актуально с развитием различных порталов, которые могут содержать наполнение разных категорий, изменяющееся во времени и/или подстраиваемое под настройки клиента.</p><p>Ставшие в последнее время популярными технологии и инструменты построения Интернет-сайтов, такие как Ajax, Macromedia Flash и другие, требуют внесения изменений и в технологии фильтрации Интернет-трафика.</p><p>Использование шифрованных каналов для взаимодействия с Интернет-сайтами обеспечивает защиту данных от перехвата третьими лицами, но в то же время, по этим каналам передачи данных могут происходить утечка важной информации или проникновение вредоносного кода в компьютерные системы.</p><p>Актуальной остается проблема интеграции средств защиты с системами, обеспечивающими функционирование ИТ-инфраструктуры, такими как прокси-серверы, веб-серверы, почтовые серверы, серверы каталогов и т.п. Разными компаниями и некоммерческими организациями разрабатываются протоколы для взаимодействия между различными системами.</p><p>О современном положении дел в этой области пойдет речь ниже.</p><div class="section" lang="ru"><div class="titlepage"><div><div><h3 class="title"><a name="id2522520"></a>Подходы к категоризации сайтов и данных</h3></div></div></div><p>Категоризация сайтов и данных, на них размещенных, может выполняться разными способами. В настоящее время выделяются следующие виды категоризации:</p><div class="orderedlist"><ol type="1"><li><p>использование предопределенных баз категорий сайтов с регулярным обновлением списков сайтов и категорий;</p></li><li><p>категоризация данных на лету путем анализа содержимого страниц;</p></li><li><p>использование данных о категории, информацию о принадлежности к которой предоставляет сам сайт.</p></li></ol></div><p>Каждый из этих методов имеет свои достоинства и недостатки.</p><div class="section" lang="ru"><div class="titlepage"><div><div><h4 class="title"><a name="id2522576"></a>Предопределенные базы категорий сайтов</h4></div></div></div><p>Использование заранее подготовленных баз адресов сайтов и связанных с ними категорий — давно используемый и хорошо зарекомендовавший себя метод. В настоящее время такие базы предоставляют многие компании, такие как Websense, Surfcontrol, ISS/Cobion, Secure Computing, Astaro AG, NetStar и другие. Некоторые компании используют эти базы только в своих продуктах, другие позволяют подключать их к продуктам третьих фирм. Наиболее полными считаются базы, предоставляемые компаниями Websense, Secure Computing, SurfControl и ISS/Cobion, они содержат информацию о миллионах сайтов на разных языках и в разных странах, что особенно актуально в эпоху глобализации.</p><p>Категоризация данных и формирование баз категорий обычно производится в полуавтоматическом режиме — сначала выполняются анализ содержимого и определение категории с помощью специально разработанных средств, которые даже могут включать в себя системы распознавания текстов в картинках. А на втором этапе полученная информация часто проверяется людьми, принимающими решение о том, к какой категории можно отнести тот или иной сайт.</p><p>Многие компании автоматически пополняют базу категорий по результатам работы у клиентов, если обнаруживается сайт, не отнесенный еще ни к какой из категорий.</p><p>В настоящее время используются два способа подключения предопределенных баз категорий сайтов:</p><div class="orderedlist"><ol type="1"><li><p>использование локальной базы категоий с регулярным ее обновлением. Данный метод очень удобен для больших организаций, имеющих выделенные серверы фильтрации и обслуживающие большое количество запросов;</p></li><li><p>использование базы категорий, размещенной на удаленном сервере. Данный метод часто применяется в различных устройствах — небольших межсетевых экранах, ADSL-модемах и т.п. Использование удаленной базы категорий немного увеличивает нагрузку на каналы, но обеспечивает использование актуальной базы категорий.</p></li></ol></div><p>К преимуществам применения предопределенных баз категорий можно отнести то, что предоставление или запрет доступа производится еще на этапе выдачи запроса клиентом, что может существенно снизить нагрузку на каналы передачи данных. А главный недостаток использования данного подхода — задержки в обновлении баз категорий сайтов, поскольку для анализа потребуется некоторое время. Кроме того, некоторые сайты достаточно часто меняют свое наполнение, из-за чего информация о категории, хранящаяся в базе адресов, становится неактуальной. Некоторые сайты также могут предоставлять доступ к разной информации, в зависимости от имени пользователя, географического региона, времени суток и т.п.</p></div><div class="section" lang="ru"><div class="titlepage"><div><div><h4 class="title"><a name="id2524106"></a>Категоризация данных на лету</h4></div></div></div><p>Категоризация сайтов на лету также осуществляется самыми разными способами. Особенно часто используются методы, основанные на статистическом подходе к анализу содержания.</p><p>Один из простых вариантов реализации такого решения —  использование байесовских алгоритмов, которые себя достаточно хорошо зарекомендовали в борьбе со спамом. Однако у этого варианта есть свои недостатки — необходимо его периодически доучивать, корректировать словари в соответствии с передаваемыми данными. Поэтому некоторые компании применяют более сложные алгоритмы определения категории сайта по содержимому в дополнение к простым способам. Например, компания ContentWatch предоставляет специальную библиотеку, которая выполняет анализ данных согласно лингвистической информации о том или ином языке и на основании этой информации может определять категорию данных.</p><p>Категоризация данных на лету позволяет быстро реагировать на появление новых сайтов, поскольку информация о категории сайта не зависит от его адреса, а только от содержания. Но такой подход имеет и недостатки —  необходимо проводить анализ всех передаваемых данных, что вызывает некоторое снижение производительности системы. Второй недостаток — необходимость поддержания актуальных баз категорий для различных языков. Тем не менее, некоторые продукты применяют этот подход с одновременным использованием баз категорий сайтов. Сюда можно отнести использование Virtual Control Agent в продуктах компании SurfControl, механизмы определения категорий данных в СКВТ "Дозор-Джет".</p></div><div class="section" lang="ru"><div class="titlepage"><div><div><h4 class="title"><a name="id2524212"></a>Данные о категории, предоставляемые сайтами</h4></div></div></div><p>Кроме баз данных адресов и категоризации содержимого на лету существует и другой подход к определению категории сайтов — сайт сам сообщает о том, к какой категории он относится.</p><p>Этот подход в первую очередь предназначен для использования домашними пользователями, когда, например, родители или учителя могут задать политику фильтрации и/или отслеживать, какие сайты посещаются.</p><p>Существует несколько путей реализации данного подхода к категоризации ресурсов:</p><div class="orderedlist"><ol type="1"><li><p>PICS (Platform for Internet Content Selection) — спецификация, разработанная консорциумом W3 около десяти лет назад и имеющая различные расширения, направленные на обеспечение надежности рейтинговой системы. Для контроля может использоваться специальное разработанное программное обеспечение, доступное для загрузки со страницы проекта. Более подробную информацию о PICS можно найти на сайте консорциума W3.org (http://www.w3.org/PICS/).</p></li><li><p>ICRA (Internet Content Rating Association) —  новая инициатива, разрабатываемая независимой некоммерческой организацией с тем же названием. Основная цель данной инициативы — защита детей от доступа к запрещенному содержимому. Данная организация имеет соглашения с множеством компаний (крупные телекоммуникационные и компании-разработчики ПО) для обеспечения более надежной защиты.</p><p>ICRA предоставляет программное обеспечение, которое позволяет проверять специальную метку, возвращаемую сайтом, и принимать решение о доступек этим данным. Программное обеспечение работает только на платформе Microsoft Windows, но благодаря открытой спецификации существует возможность создания реализаций фильтрующего ПО и для других платформ. Цели и задачи, решаемые данной организацией, а также все необходимые документы можно найти на сайте ICRA — http://www.icra.org/.</p></li></ol></div><p>К достоинствам этого подхода можно отнести то, что для обработки данных нужно только специальное программное обеспечение и нет необходимости обновлять базы адресов и/или категорий, так как вся информация передается самим сайтом. Но недостатком является то, что сайт может указывать неправильную категорию, а это приведет к неправильному предоставлению или запрещению доступа к данным. Однако эту проблему можно решить (и она уже решается) за счет использования средств подтверждения правильности данных, таких как цифровые подписи и т. п.</p></div></div><div class="section" lang="ru"><div class="titlepage"><div><div><h3 class="title"><a name="id2524365"></a>Фильтрация трафика в мире Web 2.0</h3></div></div></div><p>Массовое внедрение так называемых технологий Web 2.0 сильно усложнило контентную фильтрацию веб-трафика. Поскольку во многих случаях данные передаются отдельно от оформления, существует возможность пропуска нежелательной информации к пользователю или от пользователя. В случае работы с сайтами, применяющими такие технологии, необходимо делать комплексный анализ передаваемых данных, определяя передачу дополнительной информации и учитывая данные, собранные на предыдущих этапах.</p><p>В настоящее время ни одна из компаний, выпускающих средства для контентной фильтрации веб-трафика, не позволяет производить комплексный анализ данных, передаваемых с использованием технологий AJAX.</p></div><div class="section" lang="ru"><div class="titlepage"><div><div><h3 class="title"><a name="id2524411"></a>Интеграция с внешними системами</h3></div></div></div><p>Во многих случаях достаточно острым становится вопрос об интеграции систем контентного анализа с другими системами. При этом системы контентного анализа могут выступать как клиентами, так и серверами или в обеих ролях сразу. Для этих целей было разработано несколько стандартных протоколов — Internet Content Adaptation Protocol (ICAP), Open Pluggable Edge Services (OPES). Кроме того, некоторые производители создавали собственные протоколы для обеспечения взаимодействия конкретных продуктов друг с другом или со сторонним программным обеспечением. Сюда можно отнести протоколы Cisco Web Cache Coordination Protocol (WCCP), Check Point Content Vectoring Protocol (CVP) и другие.</p><p>Некоторые протоколы —  ICAP и OPES —  разработаны так, что могут использоваться для реализации как сервисов контентной фильтрации, так и других сервисов — переводчики, размещение рекламы, доставка данных, зависящая от политики их распространения, и т.п.</p><div class="section" lang="ru"><div class="titlepage"><div><div><h4 class="title"><a name="id2571612"></a>Протокол ICAP</h4></div></div></div><p>В настоящее время протокол ICAP пользуется популярностью среди авторов ПО для контентной фильтрации и создателей программного обеспечения для определения вредоносного содержимого (вирусы, spyware/malware). Однако стоит отметить, что ICAP в первую очередь разрабатывался для работы с HTTP, что накладывает много ограничений на его использование с другими протоколами.</p><p>ICAP принят группой Internet Engineering Task Force (IETF) в качестве стандарта. Сам протокол определяется документом "RFC 3507" с некоторыми дополнениями, изложенными в документе "ICAP Extensions draft". Эти документы и дополнительная информация доступны с сервера ICAP Forum — http://www.i-cap.org.</p><p>
          </p><div class="figure-float" style="float: left;"><div class="figure"><a name="cf.trends.fig1"></a><p class="title"><b>Рисунок 1. Схема взаимодействия серверов и клиентов ICAP</b></p><div class="figure-contents"><div class="screenshot"><div class="mediaobject"><img src="image001-ru.png" alt="Схема взаимодействия серверов и клиентов ICAP"></div></div></div></div><br class="figure-break"></div><p>
        </p><p>Архитектура системы при использовании протокола ICAP изображена на рисунке
        <a class="xref" href="ar01s04.html#cf.trends.fig1" title="Рисунок 1. Схема взаимодействия серверов и клиентов ICAP">Схема взаимодействия серверов и клиентов ICAP</a>. В качестве
        клиента ICAP выступает система, через которую передается трафик. Система,
        выполняющая анализ и обработку данных, называется сервером ICAP. Серверы ICAP
        могут выступать в роли клиентов для других серверов, что обеспечивает возможность
        стыковки нескольких сервисов для коллективной обработки одних и тех же
        данных.</p><p>Для взаимодействия между клиентом и сервером используется протокол, похожий на протокол HTTP версии 1.1, и те же способы кодирования информации. Согласно стандарту ICAP может обрабатывать как исходящий (REQMOD —  Request Modification), так и входящий (RESPMOD — Response Modification) трафик.</p><p>Решение о том, какие из передаваемых данных будут обрабатываться, принимается клиентом ICAP, в некоторых случаях это делает невозможным полный анализ данных. Настройки клиента полностью зависят от его реализации, и во многих случаях невозможноих изменить.</p><p>После получения данных от клиента сервер ICAP выполняет их обработку, а если это необходимо, то и модификацию данных. Затем данные возвращаются клиенту ICAP, и он их передает дальше серверу или клиенту, в зависимости от того, в каком направлении они передавались.</p><p>Наиболее широкое применение протокол ICAP нашел в продуктах для защиты от вредоносного кода, поскольку он позволяет использовать эти проверки в различных продуктах и не зависит от платформы, на которой выполняется клиент ICAP.</p><p>К недостаткам использования ICAP можно отнести следующее:</p><div class="orderedlist"><ol type="1"><li><p>дополнительные сетевые взаимодействия между клиентом и сервером несколько замедляют скорость передачи данных между внешними системами и потребителями информации;</p></li><li><p>существуют проверки, которые необходимо выполнять не на клиенте, а на сервере ICAP, такие как определение типа данных и т.п. Это актуально, поскольку во многих случаях клиенты ICAP ориентируются на расширение файла или на тип данных, сообщенный внешним сервером, что может стать причиной нарушения политики безопасности;</p></li><li><p>затрудненная интеграция с системами, использующими протоколы, отличные от HTTP, не позволяет использовать ICAP для глубокого анализа данных.</p></li></ol></div></div><div class="section" lang="ru"><div class="titlepage"><div><div><h4 class="title"><a name="id2572073"></a>Протокол OPES</h4></div></div></div><p>В отличие от ICAP протокол OPES разрабатывался с учетом особенностей конкретных протоколов. Кроме того, при его разработке учитывались недостатки протокола ICAP, такие как отсутствие установления подлинности клиентов и серверов, отсутствие аутентификации и др.</p><p>Так же как и ICAP, OPES принят группой Internet Engineering Task Force в качестве стандарта. Структура взаимодействия сервисов, протокол взаимодействия, требования к сервисам и решения по обеспечению безопасности сервисов изложены в документах RFC 3752, 3835, 3836, 3837 и других. Список регулярно пополняется новыми документами, описывающими применение OPES не только к обработке интернет-трафика, но и к обработке почтового трафика, а в будущем, возможно, и других видов протоколов.</p><p>
          </p><div class="figure-float" style="float: left;"><div class="figure"><a name="cf.trends.fig2"></a><p class="title"><b>Рисунок 2. Схема взаимодействия клиентов и серверов OPES</b></p><div class="figure-contents"><div class="screenshot"><div class="mediaobject"><img src="image002-ru.png" alt="Схема взаимодействия клиентов и серверов OPES"></div></div></div></div><br class="figure-break"></div><p>
        </p><p>Структура взаимодействия серверов OPES и клиентов (OPES Processor)
        изображена на рисунке <a class="xref" href="ar01s04.html#cf.trends.fig2" title="Рисунок 2. Схема взаимодействия клиентов и серверов OPES">Схема взаимодействия клиентов и серверов OPES</a>. В общих чертах она подобна схеме взаимодействия
        серверов и клиентов ICAP, но есть и существенные отличия: </p><div class="orderedlist"><ol type="1"><li><p>имеются требования к реализации клиентов OPES, что делает возможным более удобное управление ими — задание политик фильтрации и т.п.;</p></li><li><p>потребитель данных (пользовательили информационная система) может оказывать влияние на обработку данных. Например, при использовании автоматических переводчиков получаемые данные могут автоматически переводиться на тот язык, который используется пользователем;</p></li><li><p>системы, предоставляющие данные, также могут оказывать влияние на результаты обработки;</p></li><li><p>серверы обработки могут использовать для анализа данные, специфичные для протокола, по которому данные были переданы клиенту OPES;</p></li><li><p>некоторые серверы обработки данных могут получать более важные данные, если они находятся в доверительных отношениях с клиентом OPES, потребителями и/или поставщиками информации.</p></li></ol></div><p>Все перечисленные возможности зависят исключительно от конфигурации, применяемой при внедрении системы. За счет этих возможностей использование OPES более перспективно и удобно, чем использование протокола ICAP.</p><p>В скором будущем ожидается появление продуктов, поддерживающих OPES наравне с протоколом ICAP. Пионером в разработке и использовании OPES является компания Secure Computing со своей линейкой продуктов Webwasher.</p><p>Поскольку в настоящее время нет полноценных реализаций, использующих OPES, то нельзя делать окончательные выводы о недостатках данного подхода, хотя теоретически пока остается лишь один недостаток — увеличение времени обработки за счет взаимодействия между клиентами и серверами OPES.</p></div></div><div class="section" lang="ru"><div class="titlepage"><div><div><h3 class="title"><a name="id2572311"></a>HTTPS и другие виды шифрованного трафика</h3></div></div></div><p>По расчетам некоторых аналитиков, до 50% Интернет-трафика передается в зашифрованном виде. Проблема контроля шифрованного трафика сейчас актуальна для многих организаций, поскольку пользователи могут применять шифрацию для создания каналов утечки информации. Кроме того, шифрованные каналы могут использоваться и вредоносным кодом для проникновения в компьютерные системы.</p><p>Существует несколько задач, связанных с обработкой шифрованного трафика:</p><div class="orderedlist"><ol type="1"><li><p>анализ данных, передаваемых по зашифрованным каналам;</p></li><li><p>проверка сертификатов которые, используются серверами для организации шифрованных каналов.</p></li></ol></div><p>Актуальность этих задач возрастает с каждым днем.</p><div class="section" lang="ru"><div class="titlepage"><div><div><h4 class="title"><a name="id2572378"></a>Контроль передачи шифрованных данных</h4></div></div></div><p>Контроль передачи данных, пересылаемых по зашифрованным каналам, является,
        наверное, самой важной задачей для организаций, сотрудники которых имеют доступ к
        Интернет-ресурсам. Для реализации этого контроля существует подход, называемый
        "Man-in-the-Middle" (в некоторых источниках его также называют "Main-in-the
        Middle"), который может использоваться злоумышленниками для перехвата
        данных. Схема обработки данных для данного метода дана на рисунке <a class="xref" href="ar01s04.html#cf.trends.fig3" title="Рисунок 3. Процесс обработки шифрованных данных">Процесс обработки шифрованных данных</a>.</p><p>
          </p><div class="figure-float" style="float: left;"><div class="figure"><a name="cf.trends.fig3"></a><p class="title"><b>Рисунок 3. Процесс обработки шифрованных данных</b></p><div class="figure-contents"><div class="screenshot"><div class="mediaobject"><img src="image003-ru.png" alt="Процесс обработки шифрованных данных"></div></div></div></div><br class="figure-break"></div><p>
        </p><p>Процесс обработки данных выглядит следующим образом:</p><div class="orderedlist"><ol type="1"><li><p>в Интернет-броузер пользователя устанавливается специально выписанный корневой сертификат, который используется прокси-сервером для подписывания сгенеренного сертификата (без установки такого сертификата, броузер пользователя будет выдавать сообщение о том, что подписывающий сертификат выдан недоверенной организацией);</p></li><li><p>при установлении соединения с прокси-сервером происходит обмен данными, и в браузер передается специально сгенерированный сертификат с данными сервера назначения, но подписанный известным ключем, что позволяет прокси-серверу расшифровывать передаваемый траффик;</p></li><li><p>расшифрованные данные анализируются так же, как и обычный HTTP-трафик;</p></li><li><p>прокси-сервер устанавливает соединение с сервером, на который должны быть переданы данные, и использует для шифрации канала сертификат сервера;</p></li><li><p>возвращаемые от сервера данные расшифровываются, анализируются и передаются пользователю, зашифрованные сертификатом прокси-сервера.</p></li></ol></div><p>При использовании данной схемы обработки шифрованных данных могут возникать проблемы, связанные с подтверждением истинности пользователя. Кроме того, требуется выполнение работы по установке сертификата в Интернет-броузеры всех пользователей (если не установить такой сертификат, то у пользователя будет появляться сообщение о том, что сертификат подписан неизвестной компанией, что даст пользователю информацию о наблюдении за передачей данных).</p><p>Сейчас на рынке предлагаются следующие продукты для контроля передачи шифрованных данных: Webwasher SSL Scanner компании Secure Computing, Breach View SSL, WebCleaner.</p></div><div class="section" lang="ru"><div class="titlepage"><div><div><h4 class="title"><a name="id2572580"></a>Проверка подлинности сертификатов</h4></div></div></div><p>Вторая задача, возникающая при использовании шифрованных каналов передачи данных, — проверка подлинности сертификатов, предоставляемых серверами, с которыми работают пользователи.</p><p>Злоумышленники могут осуществлять атаку на информационные системы, создавая ложную запись в DNS, перенаправляющую запросы пользователя не на тот сайт, который им необходим, а на созданный самими злоумышленниками. С помощью таких подставных сайтов могут быть украдены важные данные пользователей, такие как номера кредитных карт, пароли и т.п., а также под видом обновлений программного обеспечения может быть загружен вредоносный код.</p><p>Для предотвращения подобных случаев и существует специализированное программное обеспечение, выполняющее проверку соответствия сертификатов, предоставленных сервером, тем данным, о которых они сообщают.</p><p>В случае несовпадения система может заблокировать доступ к таким сайтам или осуществить доступ после явного подтверждения пользователем. Обработка данных при этом выполняется практически тем же способом, что и при анализе данных, передаваемых по шифрованным каналам, только в этом случае анализируются не данные, а сертификат, предоставляемый сервером.</p></div></div></div><script src="http://www.google-analytics.com/urchin.js" type="text/javascript"></script><script type="text/javascript">
      _uacct = "UA-78697-3";
      urchinTracker();
    </script><div class="navfooter"><hr><table width="100%" summary="Navigation footer"><tr><td width="40%" align="left"><a accesskey="p" href="ar01s03.html">Пред.</a> </td><td width="20%" align="center"> </td><td width="40%" align="right"> <a accesskey="n" href="ar01s05.html">След.</a></td></tr><tr><td width="40%" align="left" valign="top">Современные угрозы </td><td width="20%" align="center"><a accesskey="h" href="index.html">Начало</a></td><td width="40%" align="right" valign="top"> Фильтрация почтового трафика</td></tr></table></div></body></html>
